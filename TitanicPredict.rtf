{\rtf1\ansi\ansicpg936\cocoartf1504\cocoasubrtf830
{\fonttbl\f0\fmodern\fcharset0 Courier;\f1\fmodern\fcharset0 Courier-Bold;}
{\colortbl;\red255\green255\blue255;\red49\green108\blue107;\red245\green245\blue245;\red0\green0\blue0;
\red14\green107\blue1;\red15\green112\blue1;\red169\green14\blue26;\red10\green65\blue216;\red83\green83\blue83;
\red171\green16\blue27;\red151\green0\blue255;\red0\green0\blue0;}
{\*\expandedcolortbl;;\cssrgb\c23922\c49412\c49412;\cssrgb\c96863\c96863\c96863;\cssrgb\c0\c0\c0\c70196;
\cssrgb\c0\c48235\c0;\cssrgb\c0\c50196\c0;\cssrgb\c72941\c12941\c12941;\cssrgb\c1961\c35686\c87843;\cssrgb\c40000\c40000\c40000;
\cssrgb\c73333\c13725\c13725;\cssrgb\c66667\c13333\c100000;\cssrgb\c0\c0\c0\c40000;}
\paperw11900\paperh16840\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\sl460\partightenfactor0

\f0\fs28 \cf2 \cb3 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 # This Python 3 environment comes with many helpful analytics libraries installed\cf4 \strokec4 \
\cf2 \strokec2 # It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\cf4 \strokec4 \
\cf2 \strokec2 # For example, here's several helpful packages to load in \cf4 \strokec4 \
\
\pard\pardeftab720\sl460\partightenfactor0
\cf5 \strokec5 import\cf4 \strokec4  numpy \cf5 \strokec5 as\cf4 \strokec4  np \cf2 \strokec2 # linear algebra\cf4 \strokec4 \
\cf5 \strokec5 import\cf4 \strokec4  pandas \cf5 \strokec5 as\cf4 \strokec4  pd \cf2 \strokec2 # data processing, CSV file I/O (e.g. pd.read_csv)\cf4 \strokec4 \
\
\pard\pardeftab720\sl460\partightenfactor0
\cf2 \strokec2 # Input data files are available in the "../input/" directory.\cf4 \strokec4 \
\cf2 \strokec2 # For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\cf4 \strokec4 \
\
\pard\pardeftab720\sl460\partightenfactor0
\cf5 \strokec5 from\cf4 \strokec4  subprocess \cf5 \strokec5 import\cf4 \strokec4  check_output\
\pard\pardeftab720\sl460\partightenfactor0
\cf6 \strokec6 print\cf4 \strokec4 (check_output([\cf7 \strokec7 "ls"\cf4 \strokec4 , \cf7 \strokec7 "../input"\cf4 \strokec4 ])\cf8 \strokec8 .\cf4 \strokec4 decode(\cf7 \strokec7 "utf8"\cf4 \strokec4 ))\
\pard\pardeftab720\sl460\partightenfactor0
\cf5 \strokec5 import\cf4 \strokec4  csv \cf5 \strokec5 as\cf4 \strokec4  csv\
\cf5 \strokec5 import\cf4 \strokec4  numpy \cf5 \strokec5 as\cf4 \strokec4  np\
\cf5 \strokec5 import\cf4 \strokec4  tensorflow \cf5 \strokec5 as\cf4 \strokec4  tf\
\
\cf5 \strokec5 def\cf4 \strokec4  preprocess(filename):\
    data_df \cf8 \strokec8 =\cf4 \strokec4  pd\cf8 \strokec8 .\cf4 \strokec4 read_csv(filename, header\cf8 \strokec8 =\cf9 \strokec9 0\cf4 \strokec4 )\
    data_df[\cf10 \strokec10 'Gender'\cf4 \strokec4 ] \cf8 \strokec8 =\cf4 \strokec4  data_df[\cf10 \strokec10 'Sex'\cf4 \strokec4 ]\cf8 \strokec8 .\cf4 \strokec4 map( \{\cf10 \strokec10 'female'\cf4 \strokec4 : \cf9 \strokec9 0\cf4 \strokec4 , \cf10 \strokec10 'male'\cf4 \strokec4 : \cf9 \strokec9 1\cf4 \strokec4 \} )\cf8 \strokec8 .\cf4 \strokec4 astype(\cf6 \strokec6 int\cf4 \strokec4 )\
    \cf2 \strokec2 # All missing Embarked -> just make them embark from most common place\cf4 \strokec4 \
    \cf5 \strokec5 if\cf4 \strokec4  \cf6 \strokec6 len\cf4 \strokec4 (data_df\cf8 \strokec8 .\cf4 \strokec4 Embarked[ data_df\cf8 \strokec8 .\cf4 \strokec4 Embarked\cf8 \strokec8 .\cf4 \strokec4 isnull() ]) \cf8 \strokec8 >\cf4 \strokec4  \cf9 \strokec9 0\cf4 \strokec4 :\
        data_df\cf8 \strokec8 .\cf4 \strokec4 Embarked[ data_df\cf8 \strokec8 .\cf4 \strokec4 Embarked\cf8 \strokec8 .\cf4 \strokec4 isnull() ] \cf8 \strokec8 =\cf4 \strokec4  data_df\cf8 \strokec8 .\cf4 \strokec4 Embarked\cf8 \strokec8 .\cf4 \strokec4 dropna()\cf8 \strokec8 .\cf4 \strokec4 mode()\cf8 \strokec8 .\cf4 \strokec4 values\
\
    Ports \cf8 \strokec8 =\cf4 \strokec4  \cf6 \strokec6 list\cf4 \strokec4 (\cf6 \strokec6 enumerate\cf4 \strokec4 (np\cf8 \strokec8 .\cf4 \strokec4 unique(data_df[\cf10 \strokec10 'Embarked'\cf4 \strokec4 ])))    \cf2 \strokec2 # determine all values of Embarked,\cf4 \strokec4 \
    Ports_dict \cf8 \strokec8 =\cf4 \strokec4  \{ name : i \cf5 \strokec5 for\cf4 \strokec4  i, name 
\f1\b \cf11 \strokec11 in
\f0\b0 \cf4 \strokec4  Ports \}              \cf2 \strokec2 # set up a dictionary in the form  Ports : index\cf4 \strokec4 \
    data_df\cf8 \strokec8 .\cf4 \strokec4 Embarked \cf8 \strokec8 =\cf4 \strokec4  data_df\cf8 \strokec8 .\cf4 \strokec4 Embarked\cf8 \strokec8 .\cf4 \strokec4 map( \cf5 \strokec5 lambda\cf4 \strokec4  x: Ports_dict[x])\cf8 \strokec8 .\cf4 \strokec4 astype(\cf6 \strokec6 int\cf4 \strokec4 )     \cf2 \strokec2 # Convert all Embark strings to int\cf4 \strokec4 \
\
    \cf2 \strokec2 # All the ages with no data -> make the median of all Ages\cf4 \strokec4 \
    median_age \cf8 \strokec8 =\cf4 \strokec4  data_df[\cf10 \strokec10 'Age'\cf4 \strokec4 ]\cf8 \strokec8 .\cf4 \strokec4 dropna()\cf8 \strokec8 .\cf4 \strokec4 median()\
    \cf5 \strokec5 if\cf4 \strokec4  \cf6 \strokec6 len\cf4 \strokec4 (data_df\cf8 \strokec8 .\cf4 \strokec4 Age[ data_df\cf8 \strokec8 .\cf4 \strokec4 Age\cf8 \strokec8 .\cf4 \strokec4 isnull() ]) \cf8 \strokec8 >\cf4 \strokec4  \cf9 \strokec9 0\cf4 \strokec4 :\
        data_df\cf8 \strokec8 .\cf4 \strokec4 loc[ (data_df\cf8 \strokec8 .\cf4 \strokec4 Age\cf8 \strokec8 .\cf4 \strokec4 isnull()), \cf10 \strokec10 'Age'\cf4 \strokec4 ] \cf8 \strokec8 =\cf4 \strokec4  median_age\
\
    \cf2 \strokec2 # Remove the Name column, Cabin, Ticket, and Sex (since I copied and filled it to Gender)\cf4 \strokec4 \
    data_df \cf8 \strokec8 =\cf4 \strokec4  data_df\cf8 \strokec8 .\cf4 \strokec4 drop([\cf10 \strokec10 'Name'\cf4 \strokec4 , \cf10 \strokec10 'Sex'\cf4 \strokec4 , \cf10 \strokec10 'Ticket'\cf4 \strokec4 , \cf10 \strokec10 'Cabin'\cf4 \strokec4 , \cf10 \strokec10 'PassengerId'\cf4 \strokec4 ], axis\cf8 \strokec8 =\cf9 \strokec9 1\cf4 \strokec4 )\
    \cf5 \strokec5 return\cf4 \strokec4  data_df\
\pard\pardeftab720\sl408\qr\partightenfactor0

\fs24 \cf12 \cb1 \strokec12 In\'a0[3]:\
\pard\pardeftab720\sl460\partightenfactor0

\fs28 \cf2 \cb3 \strokec2 # transform data to np.array\cf4 \strokec4 \
train_df \cf8 \strokec8 =\cf4 \strokec4  preprocess(\cf10 \strokec10 '../input/train.csv'\cf4 \strokec4 )\
test_df \cf8 \strokec8 =\cf4 \strokec4  preprocess(\cf10 \strokec10 '../input/test.csv'\cf4 \strokec4 )\
\
train_X \cf8 \strokec8 =\cf4 \strokec4  np\cf8 \strokec8 .\cf4 \strokec4 array(train_df\cf8 \strokec8 .\cf4 \strokec4 drop([\cf10 \strokec10 'Survived'\cf4 \strokec4 ],axis\cf8 \strokec8 =\cf9 \strokec9 1\cf4 \strokec4 ))\
train_X \cf8 \strokec8 =\cf4 \strokec4  train_X\cf8 \strokec8 .\cf4 \strokec4 T\
train_Y \cf8 \strokec8 =\cf4 \strokec4  np\cf8 \strokec8 .\cf4 \strokec4 matrix(train_df[\cf10 \strokec10 'Survived'\cf4 \strokec4 ])\
\cf2 \strokec2 #train_Y = train_Y.T\cf4 \strokec4 \
\cf2 \strokec2 #train_Y.reshape((train_Y.shape[0],1))\cf4 \strokec4 \
test_X \cf8 \strokec8 =\cf4 \strokec4  np\cf8 \strokec8 .\cf4 \strokec4 array(test_df)\
test_X \cf8 \strokec8 =\cf4 \strokec4  test_X\cf8 \strokec8 .\cf4 \strokec4 T\
\pard\pardeftab720\sl460\partightenfactor0
\cf6 \strokec6 print\cf4 \strokec4 (train_X\cf8 \strokec8 .\cf4 \strokec4 shape)\
\cf6 \strokec6 print\cf4 \strokec4 (train_Y\cf8 \strokec8 .\cf4 \strokec4 shape)\
\cf6 \strokec6 print\cf4 \strokec4 (test_X\cf8 \strokec8 .\cf4 \strokec4 shape)\cb1 \
\pard\pardeftab720\sl460\partightenfactor0
\cf2 \cb3 \strokec2 # build a neron network to be a classifier\cf4 \strokec4 \
X \cf8 \strokec8 =\cf4 \strokec4  tf\cf8 \strokec8 .\cf4 \strokec4 placeholder(tf\cf8 \strokec8 .\cf4 \strokec4 float32, shape\cf8 \strokec8 =\cf4 \strokec4 [\cf9 \strokec9 7\cf4 \strokec4 ,\cf2 \strokec2 None\cf4 \strokec4 ])\
Y \cf8 \strokec8 =\cf4 \strokec4  tf\cf8 \strokec8 .\cf4 \strokec4 placeholder(tf\cf8 \strokec8 .\cf4 \strokec4 float32, shape\cf8 \strokec8 =\cf4 \strokec4 [\cf9 \strokec9 1\cf4 \strokec4 ,\cf2 \strokec2 None\cf4 \strokec4 ])\
\
W1 \cf8 \strokec8 =\cf4 \strokec4  tf\cf8 \strokec8 .\cf4 \strokec4 Variable(tf\cf8 \strokec8 .\cf4 \strokec4 random_normal([\cf9 \strokec9 6\cf4 \strokec4 ,\cf9 \strokec9 7\cf4 \strokec4 ]))\
b1 \cf8 \strokec8 =\cf4 \strokec4  tf\cf8 \strokec8 .\cf4 \strokec4 Variable(tf\cf8 \strokec8 .\cf4 \strokec4 random_normal([\cf9 \strokec9 6\cf4 \strokec4 ,\cf9 \strokec9 1\cf4 \strokec4 ]))\
W2 \cf8 \strokec8 =\cf4 \strokec4  tf\cf8 \strokec8 .\cf4 \strokec4 Variable(tf\cf8 \strokec8 .\cf4 \strokec4 random_normal([\cf9 \strokec9 5\cf4 \strokec4 ,\cf9 \strokec9 6\cf4 \strokec4 ]))\
b2 \cf8 \strokec8 =\cf4 \strokec4  tf\cf8 \strokec8 .\cf4 \strokec4 Variable(tf\cf8 \strokec8 .\cf4 \strokec4 random_normal([\cf9 \strokec9 5\cf4 \strokec4 ,\cf9 \strokec9 1\cf4 \strokec4 ]))\
W3 \cf8 \strokec8 =\cf4 \strokec4  tf\cf8 \strokec8 .\cf4 \strokec4 Variable(tf\cf8 \strokec8 .\cf4 \strokec4 random_normal([\cf9 \strokec9 1\cf4 \strokec4 ,\cf9 \strokec9 5\cf4 \strokec4 ]))\
b3 \cf8 \strokec8 =\cf4 \strokec4  tf\cf8 \strokec8 .\cf4 \strokec4 Variable(tf\cf8 \strokec8 .\cf4 \strokec4 random_normal([\cf9 \strokec9 1\cf4 \strokec4 ,\cf9 \strokec9 1\cf4 \strokec4 ]))\
\
Z1 \cf8 \strokec8 =\cf4 \strokec4  tf\cf8 \strokec8 .\cf4 \strokec4 add(tf\cf8 \strokec8 .\cf4 \strokec4 matmul(W1,X),b1)\
A1 \cf8 \strokec8 =\cf4 \strokec4  tf\cf8 \strokec8 .\cf4 \strokec4 nn\cf8 \strokec8 .\cf4 \strokec4 relu(Z1)\
Z2 \cf8 \strokec8 =\cf4 \strokec4  tf\cf8 \strokec8 .\cf4 \strokec4 add(tf\cf8 \strokec8 .\cf4 \strokec4 matmul(W2,A1),b2)\
A2 \cf8 \strokec8 =\cf4 \strokec4  tf\cf8 \strokec8 .\cf4 \strokec4 nn\cf8 \strokec8 .\cf4 \strokec4 relu(Z2)\
Z3 \cf8 \strokec8 =\cf4 \strokec4  tf\cf8 \strokec8 .\cf4 \strokec4 add(tf\cf8 \strokec8 .\cf4 \strokec4 matmul(W3,A2),b3)\
hypothesis \cf8 \strokec8 =\cf4 \strokec4  tf\cf8 \strokec8 .\cf4 \strokec4 sigmoid(Z3)\
\cf2 \strokec2 #hypothesis = hypothesis > 0.5\cf4 \strokec4 \
logits \cf8 \strokec8 =\cf4 \strokec4  tf\cf8 \strokec8 .\cf4 \strokec4 transpose(hypothesis, perm\cf8 \strokec8 =\cf4 \strokec4 [\cf9 \strokec9 1\cf4 \strokec4 , \cf9 \strokec9 0\cf4 \strokec4 ])\
labels \cf8 \strokec8 =\cf4 \strokec4  tf\cf8 \strokec8 .\cf4 \strokec4 transpose(Y, perm\cf8 \strokec8 =\cf4 \strokec4 [\cf9 \strokec9 1\cf4 \strokec4 , \cf9 \strokec9 0\cf4 \strokec4 ])\
cost \cf8 \strokec8 =\cf4 \strokec4  tf\cf8 \strokec8 .\cf4 \strokec4 reduce_mean(tf\cf8 \strokec8 .\cf4 \strokec4 nn\cf8 \strokec8 .\cf4 \strokec4 sigmoid_cross_entropy_with_logits(logits\cf8 \strokec8 =\cf4 \strokec4 logits,labels \cf8 \strokec8 =\cf4 \strokec4  labels))\
optimizer \cf8 \strokec8 =\cf4 \strokec4  tf\cf8 \strokec8 .\cf4 \strokec4 train\cf8 \strokec8 .\cf4 \strokec4 AdamOptimizer(learning_rate \cf8 \strokec8 =\cf4 \strokec4  \cf9 \strokec9 0.01\cf4 \strokec4 )\cf8 \strokec8 .\cf4 \strokec4 minimize(cost)\
\
predict \cf8 \strokec8 =\cf4 \strokec4  tf\cf8 \strokec8 .\cf4 \strokec4 cast(hypothesis\cf8 \strokec8 >\cf9 \strokec9 0.5\cf4 \strokec4 ,dtype \cf8 \strokec8 =\cf4 \strokec4  tf\cf8 \strokec8 .\cf4 \strokec4 float32)\
training_accuracy \cf8 \strokec8 =\cf4 \strokec4  tf\cf8 \strokec8 .\cf4 \strokec4 reduce_mean(tf\cf8 \strokec8 .\cf4 \strokec4 cast(tf\cf8 \strokec8 .\cf4 \strokec4 equal(predict,Y),dtype\cf8 \strokec8 =\cf4 \strokec4 tf\cf8 \strokec8 .\cf4 \strokec4 float32))\
\pard\pardeftab720\sl460\partightenfactor0
\cf5 \strokec5 with\cf4 \strokec4  tf\cf8 \strokec8 .\cf4 \strokec4 Session() \cf5 \strokec5 as\cf4 \strokec4  sess:\
    sess\cf8 \strokec8 .\cf4 \strokec4 run(tf\cf8 \strokec8 .\cf4 \strokec4 global_variables_initializer())\
    \cf5 \strokec5 for\cf4 \strokec4  step 
\f1\b \cf11 \strokec11 in
\f0\b0 \cf4 \strokec4  \cf6 \strokec6 range\cf4 \strokec4 (\cf9 \strokec9 50001\cf4 \strokec4 ):\
        cost_val,_ \cf8 \strokec8 =\cf4 \strokec4  sess\cf8 \strokec8 .\cf4 \strokec4 run([cost,optimizer],feed_dict\cf8 \strokec8 =\cf4 \strokec4 \{X:train_X,Y:train_Y\})\
        \cf5 \strokec5 if\cf4 \strokec4  step \cf8 \strokec8 %\cf5 \strokec5 1000\cf4 \strokec4  ==0:\
            \cf6 \strokec6 print\cf4 \strokec4 (step,cost_val)\
    h,c,a \cf8 \strokec8 =\cf4 \strokec4  sess\cf8 \strokec8 .\cf4 \strokec4 run([hypothesis,predict,training_accuracy],feed_dict \cf8 \strokec8 =\cf4 \strokec4  \{X:train_X,Y:train_Y\})\
    \cf6 \strokec6 print\cf4 \strokec4 (\cf10 \strokec10 'training accuracy:'\cf4 \strokec4 ,a)\
    test_predict \cf8 \strokec8 =\cf4 \strokec4  sess\cf8 \strokec8 .\cf4 \strokec4 run(predict,feed_dict\cf8 \strokec8 =\cf4 \strokec4 \{X:test_X\})\
    \cf6 \strokec6 print\cf4 \strokec4 (test_predict)\
}